\chapter{Term Inference}
\label{ch:inference}

Inference is an important feature of dependent programming languages, that allows redundant parts of programs to be left out. This reduces the annotation burden in comparison with explicitly typed languages. For example, it allows you to infer the argument type of a function, if it can be inferred by the usage of the function, like in this example where the type of the argument of the polymorphic identity function can be inferred, since we pass it \verb|true| which is a boolean:
\begin{lstlisting}
let id = (\T : Type. \x: T. x);
id _ true
\end{lstlisting}

The syntax we chose is that if we want a value to be inferred, we replace it with an underscore. Other languages such as Agda allow for \emph{implicit arguments}, which are arguments that can be left out, which will then be inferred~\cite{agda, coq}. This is just syntactic sugar over the \emph{placeholders} we implement.

Furthermore, we call the inference algorithm \emph{term inference} rather than \emph{type inference}, because it can infer values other than types. For example, it can infer that the placeholder in this example must be \verb|true|:
\begin{lstlisting}
postulate f: Bool -> Type;
postulate g: f true -> Type;
\x: f _. g x
\end{lstlisting}

\section{Different Algorithms for Inference}
\label{strength-inference}

There are a lot of different algorithms for inference~\cite{typeinference}, some algorithms can solve more inference problems than others. One algorithm for unification is \emph{first-order unification} (FOU), where if at any point during type checking we assert that $\beq{e_1}{e_2}$ and either $e_1$ or $e_2$ is a free metavariable, we set the the value free metavariable to be equal to the value of the non-free metavariable. There are some situations in which this approach fails to infer a term, but in most real-world scenarios it works very well. For example, it can infer both programs in the introduction of this chapter, but it fails to infer the following program:

\begin{lstlisting}
let f = _;
\x : Type.
\g: (f x) -> Bool.
g true
\end{lstlisting}

We know that \verb|f| is a function from \verb|Type -> Type|, but it fails to infer the value of \verb|f|. Because of the way that \verb|g| is used, the type checker asserts that $\beq{f x}{Bool}$. Since x is declared as a function argument and it is completely free, this means that for any \verb|x|, \verb|f x = Bool|. But the rule above is not powerful enough to derive this, so it fails.

A more powerful algorithm that could solve this is \emph{higher-order pattern unification} as defined by Miller~\cite{Miller89}, which is implemented in Agda~\cite{agda}. Implementing this in Statix is theoretically possible\footnote{Since Statix is turing-complete}, but would be quite difficult to do in practice.

\section{Inference in Statix}
\label{statix-inference}

We would like to avoid implementing an algorithm at all, instead using Statix' built-in first-order unification to do the type inference for us. Implementing an inference algorithm in Statix is theoretically possible but this would not be a clean implementation (since Statix is a domain specific language that is not meant to implement these algorithms), and the goal is to use Statix in a way that is clean and declarative, not to do optimal inference.

However, we cannot immediately use Statix' built-in first-order unification (which acts in the meta language, Statix) to implement first-order unification in the object language. Ideally when implementing beta equality when we encounter $\beq{e_1}{e_2}$ we would check if $e_1$ is a free variable, but Statix does not allow for querying whether variables are free. The reason that Statix does not allow this is that it is non-trivial to guarantee confluence if this feature is added to the language.

Instead, we will be implementing a novel, less powerful form of first-order unification. This will work by explicitly denoting which variables \emph{could be} free, and explicitly handling these cases in a way that approximates first-order unification. We will name this algorithm \emph{approximated first-order unification (AFOU)}.

\section{Implementing AFOU}
\label{implementing-inference}

First, we introduce a new constructor \verb|Infer : Expr -> Expr|, which denotes the variables which could be free. The constructor is introduced when we encounter a placeholder.
\begin{lstlisting}
typeOfExpr(s, Var(Syn("_"))) = (Infer(q), qt) :-
	(_, qt) == typeOfExpr(sEmpty(), q).
\end{lstlisting}

Note that the type of \verb|typeOfExpr| has changed, it now returns two expressions, the first being the same expression that was passed in except with placeholders replaced with \verb|Infer| constructors, and the second being the type.
\begin{lstlisting}
typeOfExpr : scope * Expr -> Expr * Expr
\end{lstlisting}

Next when we type-check an \verb|Infer| expression we just type-check the meta-variable inside. This will wait until the value of the meta-variable is known before type-checking, which is the behavior we want.
\begin{lstlisting}
typeOfExpr_(s, Infer(q)) = (Infer(q), t) :-
	typeOfExpr_(s, q) == (_, t).
\end{lstlisting}

When beta reducing we deliberately keep the \verb|Infer| expression intact, since we want to keep the information that it is an expression that might have to be inferred during beta equality checks.
\begin{lstlisting}
betaReduce_((_, Infer(e))) = Infer(e).
\end{lstlisting}

Finally, the difficult part of handling inference in beta equality. There are four different cases that involve \verb|Infer| expressions in beta equality, these are:

\begin{enumerate}
	\item A value \verb|e1| on the left, an infer expression on the right. In this case we simply want to set the metavariable equal to \verb|e1|. For example:
	\begin{lstlisting}
expectBetaEq((s1, e1@Type(_)), (_, Infer(e2))) :- e1 == e2.
expectBetaEq((s1, e1@BoolTrue()), (_, Infer(e2))) :- e1 == e2.
expectBetaEq((s1, e1@BoolFalse()), (_, Infer(e2))) :- e1 == e2.
expectBetaEq((s1, e1@BoolType()), (_, Infer(e2))) :- e1 == e2.
	\end{lstlisting}

	\item A complex expression \verb|e1| on the left, an infer expression on the right. In this case, we know what top-level constructor of the metavariable should be, but not necessarily the entire constructor (there might be infers in \verb|e1|). We introduce new \verb|Infer| expressions on the left, and call \verb|expectBetaEq| recursively. A simple example for \verb|BoolIf| is below:
	\begin{lstlisting}
expectBetaEq((s1, e1@BoolIf(c1, t1, b1)), (_, Infer(e2))) :-
	e2 == BoolIf(Infer(c2), Infer(t2), Infer(b2)),
	expectBetaEq((s1, e1), (sEmpty(), e2)).
	\end{lstlisting}
	\verb|FnType| and \verb|FnConstruct| work similarly, but we don't only have sub-expressions but also a name to consider. Sadly, this is the first case where we have to approximate. 
	\begin{lstlisting}
expectBetaEq((s1, e1@FnConstruct(arg_name1, arg_type1, body1)), 
	(_, Infer(e2))) :-
	e2 == FnConstruct(arg_name1, Infer(arg_type2), Infer(body2)),
	expectBetaEq_((s1, e1), (sEmpty(), e2)).
	\end{lstlisting}
	\label{inf-case2}
	Ideally, we would generate a new name if \verb|e2| is a unresolved metavariable, otherwise using the already generated name. We can't query whether \verb|e2| is free, so as a best-attempt we always assume that \verb|e2| is free and generate a new name, this will fail in some cases. We will discuss this in the next section.
	
	\item An infer expression on the left, any expression on the right. We should not duplicate the previous two rules, instead, we can just swap the two expressions and re-use the rules above.
\begin{lstlisting}
expectBetaEq((_, Infer(e1)), (s2, e2)) :-
	expectBetaEq((s2, e2), (_, Infer(e1))).
\end{lstlisting}

	\item \label{inf-case4} An infer expression on both sides. Here, more approximation is required. In normal first-order unification, we would see if either side is known, and possible apply one of the rules above depending on the result. This is not possible, so we're going to do something that approximates first-order unification: just set both sides to be equal. This is an approximation because this might fail if both sides are equal under beta equality but not identical. This approximation is analyzed in section \ref{analysing-inference}.
\begin{lstlisting}
expectBetaEq((_, Infer(e1)), (_, Infer(e2))) :-
	e1 == e2.
\end{lstlisting}
	
\end{enumerate}

\section{Analysis of the Approximation}
\label{analysing-inference}

The only difference between AFOU and FOU is case \ref{inf-case2} (for functions) and case \ref{inf-case4}. 

In case \ref{inf-case2}, we force the name of the function constructors to be equal. Ideally, we would generate a fresh name for the variable if and only if no name has been generated for it yet, but there is no way to tell whether this is the case so we use this approximation.

In case \ref{inf-case4}, instead of asserting that both sides are equal under beta equality, we assert that both sides are identical. Both sides being identical implies that they are beta-equal, so this approximation is sound, meaning there is no program that AFOU can infer but FOU cannot. 

The approximations are not complete: There are situations where AFOU fails to infer a program that FOU can infer. However, these programs are surprisingly uncommon considering how rough the approximations are. Inference may fail when we attempt to infer function values, and two functions are inferred that are beta-equal, and they are beta-equal but not identical. An example of a program where these approximation fails is:

\begin{lstlisting}
postulate f : (A : Type -> _: A -> _: A -> A);
postulate u : X : Bool -> Bool;
postulate v : Y : Bool -> Bool;
f _ u v
\end{lstlisting}

We could solve this problem in two ways:

\begin{enumerate}
	\item We could always beta-reduce terms completely to their normal form, then terms that are beta-equal are also identical up to alpha equality. This would solve the problem in case \ref{inf-case4}, but the problem of case \ref{inf-case2} would remain. Furthermore, doing all this beta reduction is terrible for the performance of the type checker: Beta-reducing terms may take an arbitrary amount of time, though it is guaranteed to terminate since the Calculus of Constructions is strongly normalizing~\cite{Coquand_Huet_1988}.
	\item Ideally, we want a declarative definition of the problem. To do this, we need to be able to declare that two terms that are not identical are equal, which is possible under \emph{equational unification}~\cite[Section 2.1]{Siekmann86}. If this system was added to Statix, this would make implementing more powerful inference algorithms cleanly possible. This idea is explored further in chapter \ref{ch:comp-lambdapi}.
\end{enumerate}

We have now shown how to add inference to the implementation. Next, we will add Inductive Datatypes (chapter~\ref{ch:datatypes}) and Universes (chapter~\ref{ch:universes}) to the implementation.

